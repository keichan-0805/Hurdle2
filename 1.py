import streamlit as st
import pandas as pd
from janome.tokenizer import Tokenizer
import random

# ãƒãƒ¼ãƒ‰ãƒ«ç·´ç¿’ãƒ¡ãƒ‹ãƒ¥ãƒ¼CSVèª­ã¿è¾¼ã¿
df = pd.read_csv("hurdle_data_for_streamlit.csv")

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("110mãƒãƒ¼ãƒ‰ãƒ«ç·´ç¿’ãƒ¡ãƒ‹ãƒ¥ãƒ¼ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ")

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
age = st.number_input("ã‚ãªãŸã®å¹´é½¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", min_value=10, max_value=100, value=15)
experience = st.number_input("ç«¶æŠ€æ­´ï¼ˆå¹´æ•°ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", min_value=0, max_value=20, value=2)
goal_input = st.text_input("ä¸Šé”ã—ãŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã‚¹ãƒ”ãƒ¼ãƒ‰å¼·åŒ–ã€ãƒ•ã‚©ãƒ¼ãƒ æ”¹å–„ ãªã©ï¼‰")

if st.button("ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ææ¡ˆï¼") and goal_input:
    # å½¢æ…‹ç´ è§£æ
    tokenizer = Tokenizer()
    tokens = tokenizer.tokenize(goal_input, wakati=False)
    keywords = [token.surface for token in tokens if "åè©" in token.part_of_speech]

    # çµŒé¨“å¹´æ•°ã«ã‚ˆã‚‹å‰²åˆæ±ºå®šï¼ˆä»®ã®åˆ†é¡ï¼‰
    if experience <= 2:
        ratio = {'ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ»ãƒ¢ãƒ“ãƒªãƒ†ã‚£å‘ä¸Š': 0.3, 'åŸºç¤æŠ€è¡“ï¼ˆãƒªã‚ºãƒ ãƒ»å‹•ä½œã®ç¿’å¾—ï¼‰': 0.3, 'å°‚é–€æŠ€è¡“ï¼ˆãƒãƒ¼ãƒ‰ãƒ«ç·´ç¿’ï¼‰': 0.4}
    elif 3 <= experience <= 5:
        ratio = {'å°‚é–€æŠ€è¡“ï¼ˆãƒãƒ¼ãƒ‰ãƒ«ç·´ç¿’ï¼‰': 0.4, 'ã‚¹ãƒ—ãƒªãƒ³ãƒˆå¼·åŒ–': 0.3, 'ç­‹åŠ›å¼·åŒ–': 0.3}
    else:
        ratio = {'ã‚¹ãƒ—ãƒªãƒ³ãƒˆå¼·åŒ–': 0.4, 'ç­‹åŠ›å¼·åŒ–': 0.3, 'å°‚é–€æŠ€è¡“ï¼ˆãƒãƒ¼ãƒ‰ãƒ«ç·´ç¿’ï¼‰': 0.3}

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_df = pd.DataFrame()
    for kw in keywords:
        filtered_df = pd.concat([filtered_df, df[df["å¾—ã‚‰ã‚Œã‚‹åŠ¹æœ"].str.contains(kw, na=False)]])
    filtered_df = filtered_df.drop_duplicates()
    filtered_df = filtered_df[filtered_df["é©åˆ‡ãªå¹´é½¢"] <= age]

    # ç¨®é¡ã”ã¨ã«æŠ½å‡º
    final_output = pd.DataFrame()
    for t_type, r in ratio.items():
        subset = filtered_df[filtered_df["ç¨®é¡"] == t_type]
        n_samples = max(1, int(len(filtered_df) * r))
        final_output = pd.concat([final_output, subset.sample(n=min(n_samples, len(subset)), random_state=42)])

    # å‡ºåŠ›
    if not final_output.empty:
        st.subheader(f"ğŸ¯ ç«¶æŠ€æ­´{experience}å¹´ã®ã‚ãªãŸã«ãŠã™ã™ã‚ã®ãƒãƒ¼ãƒ‰ãƒ«ç·´ç¿’ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        for _, row in final_output.iterrows():
            st.markdown(f"### â— ãƒ¡ãƒ‹ãƒ¥ãƒ¼åï¼š{row['ãƒ¡ãƒ‹ãƒ¥ãƒ¼å']}")
            st.write(f"ãƒ»èª¬æ˜ï¼š{row['ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®èª¬æ˜']}")
            st.write(f"ãƒ»åŠ¹æœï¼š{row['å¾—ã‚‰ã‚Œã‚‹åŠ¹æœ']}")
            st.write(f"ãƒ»å½¢å¼ï¼š{row['ç¨®é¡']}")
            st.write(f"ãƒ»æ¨å¥¨å¹´é½¢ï¼š{row['é©åˆ‡ãªå¹´é½¢']}æ­³ä»¥ä¸Š")
            st.markdown("---")
    else:
        st.warning("è©²å½“ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å…¥åŠ›å†…å®¹ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
